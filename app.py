%%writefile app.py
from flask import Flask, render_template, request, jsonify
import boto3
import cv2
import numpy as np
import base64
import io
from PIL import Image, ImageDraw, ImageFont

app = Flask(__name__)

# --- ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®š ---
REGION_NAME = "ap-northeast-1"
# --------------------

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/analyze', methods=['POST'])
def analyze():
    try:
        data = request.json
        img_data_b64 = data['image'].split(',')[1]
        
        img_bytes = base64.b64decode(img_data_b64)
        image = Image.open(io.BytesIO(img_bytes))
        
        # PILå½¢å¼(RGB)ã®ã¾ã¾å‡¦ç†é–‹å§‹
        img_w, img_h = image.size

        # AWSã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä½œæˆ
        rekognition = boto3.client('rekognition', region_name=REGION_NAME)
        polly = boto3.client('polly', region_name=REGION_NAME)
        # ã€è¿½åŠ ã€‘ç¿»è¨³ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        translate = boto3.client('translate', region_name=REGION_NAME)

        # èªè­˜å®Ÿè¡Œ
        response = rekognition.detect_labels(
            Image={'Bytes': img_bytes}, MaxLabels=20, MinConfidence=50
        )
        labels = response['Labels']
        
        # --- è¨ºæ–­ãƒ¬ãƒãƒ¼ãƒˆç”¨ ---
        debug_lines = ["ðŸ“¸ è§£æžå®Œäº†", "--- ãƒˆãƒƒãƒ—5 (æ—¥æœ¬èªžå¤‰æ›) ---"]

        # æç”»ã®æº–å‚™ï¼ˆæ—¥æœ¬èªžå¯¾å¿œã®ãŸã‚Pillowã‚’ä½¿ç”¨ï¼‰
        draw = ImageDraw.Draw(image)
        try:
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚©ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã‚€ (ã‚µã‚¤ã‚º30)
            font = ImageFont.truetype("static/font.ttf", 30)
        except:
            font = ImageFont.load_default() # å¤±æ•—ã—ãŸã‚‰ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆæ—¥æœ¬èªžå‡ºãªã„ï¼‰

        speech_text = ""
        found_main_object = False

        # ä¸Šä½5ã¤ã‚’ãƒ«ãƒ¼ãƒ—
        for i, label in enumerate(labels[:5]):
            en_name = label['Name']
            conf = label['Confidence']
            
            # ã€è¿½åŠ ã€‘è‹±èªž -> æ—¥æœ¬èªžã¸ç¿»è¨³
            trans_res = translate.translate_text(
                Text=en_name, SourceLanguageCode='en', TargetLanguageCode='ja'
            )
            ja_name = trans_res['TranslatedText']

            instances = label.get('Instances', [])
            status = "æž ãªã—"

            if len(instances) > 0:
                status = "âœ… æž ã‚ã‚Š"
                
                # 1ä½ã®æž ä»˜ãç‰©ä½“ã‚’ãƒ¡ã‚¤ãƒ³ã®éŸ³å£°ã«ã™ã‚‹
                if not found_main_object:
                    speech_text = f"{ja_name}ã‚’è¦‹ã¤ã‘ã¾ã—ãŸ"
                    found_main_object = True

                for instance in instances:
                    box = instance['BoundingBox']
                    x1 = box['Left'] * img_w
                    y1 = box['Top'] * img_h
                    x2 = (box['Left'] + box['Width']) * img_w
                    y2 = (box['Top'] + box['Height']) * img_h
                    
                    # æž ã‚’æã (ç·‘è‰²)
                    draw.rectangle([x1, y1, x2, y2], outline=(0, 255, 0), width=5)
                    
                    # æ—¥æœ¬èªžãƒ†ã‚­ã‚¹ãƒˆã‚’æããŸã‚ã®èƒŒæ™¯ï¼ˆæ–‡å­—ãŒèª­ã¿ã‚„ã™ã„ã‚ˆã†ã«é»’èƒŒæ™¯ï¼‰
                    text_w = draw.textlength(ja_name, font=font)
                    text_bg = [x1, y1 - 35, x1 + text_w + 10, y1]
                    draw.rectangle(text_bg, fill=(0, 255, 0))
                    
                    # æ—¥æœ¬èªžãƒ†ã‚­ã‚¹ãƒˆã‚’æç”» (ç™½æ–‡å­—)
                    draw.text((x1 + 5, y1 - 35), ja_name, font=font, fill=(255, 255, 255))
            
            debug_lines.append(f"{i+1}. {en_name} -> ã€Œ{ja_name}ã€ ({status})")

        result_text = "\n".join(debug_lines)

        # éŸ³å£°ãƒ†ã‚­ã‚¹ãƒˆãŒãªã„å ´åˆï¼ˆæž ãªã—ï¼‰
        if not speech_text:
            if labels:
                # 1ä½ã®ãƒ©ãƒ™ãƒ«ã‚’ç¿»è¨³ã—ã¦å–‹ã‚‹
                top_en = labels[0]['Name']
                top_trans = translate.translate_text(Text=top_en, SourceLanguageCode='en', TargetLanguageCode='ja')
                top_ja = top_trans['TranslatedText']
                speech_text = f"ãŸã¶ã‚“ã€{top_ja}ã ã¨æ€ã„ã¾ã™"
            else:
                speech_text = "ä½•ã‚‚ã‚ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"

        # éŸ³å£°åˆæˆ
        polly_res = polly.synthesize_speech(
            Text=speech_text, OutputFormat='mp3', VoiceId='Kazuha', Engine='neural'
        )
        audio_stream = polly_res['AudioStream'].read()
        audio_b64 = base64.b64encode(audio_stream).decode()

        # ç”»åƒã‚’Base64ã«å¤‰æ› (PIL -> Bytes)
        buf = io.BytesIO()
        image.save(buf, format='JPEG')
        processed_img_b64 = "data:image/jpeg;base64," + base64.b64encode(buf.getvalue()).decode()

        return jsonify({
            'image': processed_img_b64,
            'text': result_text,
            'audio': audio_b64
        })

    except Exception as e:
        return jsonify({'error': str(e)})

if __name__ == '__main__':
    app.run(port=5000)
